{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "practice_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uVzFtr6HeAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
        "import re\n",
        "import string\n",
        "import os\n",
        "\n",
        "from string import punctuation\n",
        "from collections import defaultdict\n",
        "from nltk import FreqDist\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer as countVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
        "\n",
        "def remove_URL(text):\n",
        "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return url.sub(r'', text)\n",
        "\n",
        "\n",
        "def remove_punct(text):\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    return text.translate(table)\n",
        "\n",
        "\n",
        "train_df = pd.read_csv(\"./data/train.csv\")\n",
        "test_df = pd.read_csv(\"./data/test.csv\")\n",
        "submission = pd.read_csv(\"./data/sample_submission.csv\")\n",
        "\n",
        "print(train_df.head(10))\n",
        "\n",
        "data = pd.concat([train_df, test_df], axis=0, sort=False)\n",
        "\n",
        "print(\"Number of unique locations: \", data.location.nunique())\n",
        "\n",
        "\n",
        "print(\"Missing values:\")\n",
        "data.isna().sum()\n",
        "data.location.fillna(\"None\", inplace=True)\n",
        "data['text'] = data['text'].apply(lambda x: remove_URL(x))\n",
        "data['text'] = data['text'].apply(lambda x: remove_punct(x))\n",
        "\n",
        "vectorizer = feature_extraction.text.CountVectorizer()\n",
        "\n",
        "train_v = vectorizer.fit_transform(train_df[\"text\"])\n",
        "test_v = vectorizer.transform(test_df[\"text\"])\n",
        "\n",
        "linear_classifier = linear_model.RidgeClassifier()\n",
        "score = model_selection.cross_val_score(linear_classifier, train_v, train_df[\"target\"], cv=3, scoring=\"f1\")\n",
        "print(score)\n",
        "linear_classifier.fit(train_v, train_df[\"target\"])\n",
        "submission[\"target\"] = linear_classifier.predict(test_v)\n",
        "print(submission.head())\n",
        "submission.to_csv('submission.csv', index=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}